---
title: "Semi-Supervised Neural Processes for Articulated Object Interaction"
collection: papers
permalink: /_papers/2024-07-15-ssnps
excerpt: 'This paper addresses the challenge of limited labeled action data for robotic object manipulation by introducing the Semi-Supervised Neural Process (SSNP). SSNP combines small amounts of labeled interaction data with abundant unlabeled visual data, using a jointly trained reward-prediction and autoencoding framework to extract task-relevant features. This approach reduces the need for extensive retraining and computational resources while improving generalization. The model outperforms other semi-supervised methods in a door-opening task, achieving superior performance with significantly less data.'
date: 2024-07-15
venue: 'Robotics: Science and Systems 2024 Workshop on Structural Priors as Inductive Biases for Learning Robot Dynamics'
slidesurl: 'https://drive.google.com/file/d/1H4tuTR8GxRnRrj3J_iJxtysVKnaRlJcZ'
paperurl: 'https://drive.google.com/file/d/1X9hYCU5t0aro-Euw3VYxST6ecPaSCHVG/view'
citation: 'Semi-Supervised Neural Processes for Articulated Object Interaction. Emily Liu, Michael Noseworthy, Nicholas Roy. RSS 2024 Workshop on Structural Priors as Inductive Biases for Learning Robot Dynamics. '
---

The scarcity of labeled action data poses a considerable challenge for developing machine learning algorithms for robotic object manipulation. It is expensive and often infeasible for a robot to interact with many objects. Conversely, visual data of objects, without interaction, is abundantly available and can be leveraged for pretraining and feature extraction. However, current methods that rely on image data for pretraining do not easily adapt to task-specific predictions, since the learned features are not guaranteed to be relevant. This paper introduces the Semi-Supervised Neural Process (SSNP): an adaptive reward-prediction model designed for scenarios in which only a small subset of objects have labeled interaction data. In addition to predicting reward labels, the latent-space of the SSNP is jointly trained with an autoencoding objective using passive data from a much larger set of objects. Jointly training with both types of data allows the model to focus more effectively on generalizable features and minimizes the need for extensive retraining, thereby reducing computational demands. The efficacy of SSNP is demonstrated through a door-opening task, leading to better performance than other semi-supervised methods, and only using a fraction of the data compared to other adaptive models.